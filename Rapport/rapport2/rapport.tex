%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University/School Laboratory Report
% LaTeX Template
% Version 4.0 (March 21, 2022)
%
% This template originates from:
% https://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@latextemplates.com)
% Linux and Unix Users Group at Virginia Tech Wiki
%
% License:
% CC BY-NC-SA 4.0 (https://creativecommons.org/licenses/by-nc-sa/4.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
	a4paper, % Paper size, specify a4paper (A4) or letterpaper (US letter)
	10pt, % Default font size, specify 10pt, 11pt or 12pt
]{CSUniSchoolLabReport}


\addbibresource{sample.bib} % Bibliography file (located in the same folder as the template)

%----------------------------------------------------------------------------------------
%	REPORT INFORMATION
%----------------------------------------------------------------------------------------

\title{MA-CSEL \\ Conception syst\`eme Embarqué Linux } % Report title

\author{Kirill \textsc{Goundiaev} \& Tanguy \textsc{Dietrich}} % Author name(s), add additional authors like: '\& James \textsc{Smith}'

\fancyhead[RE,LO]{Kirill Goundiaev \& Tanguy Dietrich}
\fancyhead[CE,CO]{\today}
\fancyhead[LE,RO]{MA-CSEL}

\fancyfoot[RE,LO]{MSE}
\fancyfoot[CE,CO]{\thepage} % this dicard page number dont touch
\fancyfoot[LE,RO]{HES-SO}
\date{\today} % Date of the report


% add image on the left top corner
% Definition of \maketitle
\makeatletter         
\def\@maketitle{
\raggedright
% \includegraphics[width = 60mm]{Figures/MSE.png}\\[8ex]
\includegraphics[width = 180mm]{Figures/ImageTitle.png}\\[8ex]
\begin{center}{}
{\Huge \@title }\\[4ex] 
{\Large  \@author}\\[4ex] 
\@date\\[8ex]
% \includegraphics[width = 40mm]{Figures/HESSO.png}
\end{center}}
\makeatother

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert the title, author and date using the information specified above

% add an image
\begin{figure}[H] % Example image
\center{\includegraphics[width=0.35\linewidth]{EMbeddedLinuxLogo}}
% \caption{Example image.}
\label{fig:speciation}
\end{figure}


%  to make a guard page
\newpage

% generate the summary table
\tableofcontents
\newpage


\section{Objectif}

This is my link: \footnote{\href{http://www.latex-tutorial.com}{http://www.latex-tutorial.com}}.

\section{Programmation Système}

\subsection{Système de fichier}\label{filesystem}
L'objectif de cet exercice est de reprendre un code faisant clignoter une LED utilisant 100\% d'un coeur du processeur et de le modifier afin qu'il utilise le système de fichier virtuel pour contrôler la LED. Au démarrage, la LED clignote à une fréquence de 2Hz. Les boutons nous permettent d'augmenter, diminuer ou réinitialiser la fréquence de clignotement. Les changements de fréquence de la LED sont reportés avec $syslog$.\\
Pour commencer, nous ouvrons les descripteurs de fichier des boutons d'une manière similaire à celle utilisée pour la LED avec quelques modifications. La fonction ci-dessous permet de configurer les GPIOs des boutons en entrée, avec un détecteur de flanc montant. Elle retourne le descripteur de fichier de la valeur du bouton.\\

\begin{lstlisting}[style=CStyle, caption=Fonction d'ouverture et configuration de boutton, firstnumber=1]{Name}
int open_button(const char *gpio_path, const char *gpio_num){
	// unexport pin out of sysfs (reinitialization)
	int f = open(GPIO_UNEXPORT, O_WRONLY);
	write(f, gpio_num, strlen(gpio_num));
	close(f);

	// export pin to sysfs
	f = open(GPIO_EXPORT, O_WRONLY);
	write(f, gpio_num, strlen(gpio_num));
	close(f);

	// config pin
	char *path = malloc(strlen(gpio_path) + strlen("/direction") + 1);
	strcpy(path, gpio_path);
	strcat(path, "/direction");
	f = open(path, O_WRONLY);
	write(f, "in", 2);
	close(f);
	free(path);

	// config edge
	path = malloc(strlen(gpio_path) + strlen("/edge") + 1);
	strcpy(path, gpio_path);
	strcat(path, "/edge");
	f = open(path, O_WRONLY);
	write(f, "rising", 6);
	close(f);
	free(path);

	// open gpio value attribute
	path = malloc(strlen(gpio_path) + strlen("/value") + 1);
	strcpy(path, gpio_path);
	strcat(path, "/value");
	f = open(path, O_RDWR);
	free(path);
	return f;
}
\end{lstlisting}

Ces descripteurs de fichier sont placés dans un tableau de structure que nous avons créé, qui stocke l'entité avec son descripteur de fichier. Ce qui nous permet d'accéder plus facilement à tous nos descripteurs. Cette structure comporte également une variable nous permettant de savoir si l'évènement arrive pour la première fois pour éviter le 'faux' premier évènement des boutons.

Nous avons ensuite initialisé le timer\footnote{\href{https://man7.org/linux/man-pages/man2/timerfd_create.2.html}{https://man7.org/linux/man-pages/man2/timerfd\_create.2.html}}. 
Ce timer nous permet de générer un évènement à interval régulier. Nous avons utilisé la fonction $timerfd\_settime()$ pour configurer le timer. Cette fonction prend en paramètre une structure qui contient le temps avant le premier évènement et le temps entre chaque évènement.
\begin{lstlisting}[style=CStyle, caption=Initialisation du timer, firstnumber=1]{Name}
int open_timer(){
	int fd = timerfd_create(CLOCK_MONOTONIC, 0);
    if (fd == -1) {
        printf("error timerfd_create: %s\n", strerror(errno));
        return 1;
    }
    // default 2Hz => 500ms
    struct itimerspec new_value;
    // interval for periodic timer
    new_value.it_interval.tv_sec = 0;
    new_value.it_interval.tv_nsec = DEFAULT_PERIOD; 

    // initial expiration (timer before first expiration)
    new_value.it_value.tv_sec = 1;
    new_value.it_value.tv_nsec = 0;
    if (timerfd_settime(fd, 0, &new_value, NULL) == -1) {
        printf("error timerfd_settime: %s\n", strerror(errno));
        return 1;
    }
    syslog(LOG_INFO, "frequence: %.5fHz", S_IN_NSEC / (double)DEFAULT_PERIOD);
    return fd;
}
\end{lstlisting}

Une fois que nos périphériques sont correctement initialisés, nous créons un $epoll$ qui nous permet de multiplexer la surveillance de nos descripteurs de fichier. Nous y ajoutons nos descripteurs de fichier avec l'évènement qui leur sont associés. Dans notre cas, les boutons sont associés à l'évènement $EPOLLET$ pour détecter le flanc montant et le timer à l'évènement $EPOLLIN$ qui permet de recevoir un évènement à chaque fois que le timer a expiré. La fonction $epoll\_ctl$ nous permet d'ajouter le contexte à surveiller dans l'$epoll$. Et enfin, la fonction $epoll\_wait$ nous permet d'attendre l'arrivée d'un évènement sur tous nos descripteurs de fichier virtuel.

Voici notre boucle principale qui permet de surveiller les évènements sur nos descripteurs de fichier.

\begin{lstlisting}[style=CStyle, caption=Boucle principale, firstnumber=1]{Name}
while(1){
	// wait for event
	struct epoll_event event_arrived[5];
	int nr = epoll_wait(epfd, event_arrived, 5, -1);
	if (nr == -1){
		printf("error epoll_wait: %s\n", strerror(errno));
		return 1;
	}
	for (int i = 0; i < nr; i++){
		my_context *ctx = event_arrived[i].data.ptr;
		switch (ctx->ev)
		{
		case EV_BTN_1: // increase frequence
		case EV_BTN_2: // resert frequence
		case EV_BTN_3: // decrease frequence
			if (ctx->first_done == 0){
				ctx->first_done = 1;
				break;
			}
			button_action(ctx->ev, 0);
			break;
		case EV_TIMER:
			read(ctx->fd, &time, sizeof(time));
			change_led();
			break;
		default:
			printf("error: unknow event\n");
			break;
		}
	}
}
\end{lstlisting}

Nous commençons par une attente passive sur l'arrivée d'un évènement sur nos descripteurs de fichier. Une fois que nous avons reçu un évènement, nous regardons quel est le contexte associé à ce dernier. Si c'est un bouton, nous appelons la fonction $button\_action$ qui permet de modifier la fréquence du timer, si ce n'est pas le premier évènement. Si c'est le timer, nous appelons la fonction $change\_led$ qui permet de changer l'état de la LED.\\
La fonction $change\_led$ écrit successivement 1 et 0 dans le descripteur de fichier de la LED afin de la faire clignoter. La fonction $button\_action$ quant à elle identifie quel bouton a été pressé et modifie la fréquence du timer en fonction du bouton. Cette fonction prend un paramètre supplémentaire qui nous permet de choisir si nous voulons finir le cycle actuel du timer ou le faire passer directement sur la nouvelle fréquence. Nous gérons également l'underflow et l'overflow de la fréquence.
\begin{lstlisting}[style=CStyle, caption=Routine LED et boutton, firstnumber=1]{Name}
void change_led(){
	static int cpt = 0;
	cpt = (cpt + 1) % 2;
	pwrite(ctx[FD_LED].fd, cpt ? "1" : "0", sizeof("0"), 0);
}

void button_action(enum my_event ev, int wait_for_first_event){
	static uint64_t period = 0;
	struct itimerspec current_value;
	struct itimerspec new_value;
	uint64_t last_period;

	switch (ev){
	case EV_BTN_1: // increase frequence
		period /= 2;
		if(period == 0){
			period = 1;
		}
		break;
	case EV_BTN_2: // resert frequence
		period = DEFAULT_PERIOD;
		break;
	case EV_BTN_3: // decrease frequence
		last_period = period;
		period *= 2;
		if(period < last_period){
			period = last_period;
		}
		break;
	default:
		printf("error: unused event\n");
		break;
	}
	// interval for new periodic timer
	new_value.it_interval.tv_sec = period / S_IN_NSEC;
	new_value.it_interval.tv_nsec = period % S_IN_NSEC;
	
	// if complete current period
	if(wait_for_first_event){
		// time until next expiration
		if(timerfd_gettime(ctx[EV_TIMER].fd, &current_value) == -1){
			printf("error timerfd_gettime: %s\n", strerror(errno));
			return;
		}
		new_value.it_value.tv_sec = current_value.it_value.tv_sec;
		new_value.it_value.tv_nsec = current_value.it_value.tv_nsec+1;
	}else{// direct reset timer
		new_value.it_value.tv_sec = 0;
		new_value.it_value.tv_nsec = 1;// +1 to force to start timer
	}
	if (timerfd_settime(ctx[EV_TIMER].fd, 0, &new_value, NULL) == -1) {
		printf("error timerfd_settime: %s\n", strerror(errno));
		return;
	}
	syslog(LOG_INFO, "frequence: %.5fHz", S_IN_NSEC / (double)period);
}
\end{lstlisting}

Notre code fonctionne correctement selon les spécifications. Nous avons également ajouté un $syslog$\footnote{\href{https://www.gnu.org/software/libc/manual/html_node/Syslog-Example.html}{https://www.gnu.org/software/libc/manual/html\_node/Syslog-Example.html}} qui nous permet de voir les changements de fréquence de la LED.\\
Nous avons pu bien visualiser avec $htop$ que notre programme n'utilise plus 100\% du CPU si la fréquence n'est pas trop élevée. Quand la période diminuer à quelques nanoseconde, les évènements arrivent trop rapidement et nous pouvons observer la croissance de l'utilisation du CPU.\\
Cet exercice était particulièrement intéressant, car il nous a permis d'utiliser le système de fichier virtuel de Linux pour contrôler nos périphériques. Nous avons également pu voir l'importance de la gestion des évènements pour la programmation système. La gestion des évènements en utilisant $epoll$ avec un multiplexage apporte une nouvelle esthétique au code que nous avons bien apprécié.

\subsection{Multiprocessing et Ordonnanceur}\label{multiprocess}
\subsubsection{Exercice 1 Processus et signaux}\label{MPEx1}
Le but de cet exercice est de mettre en place une communication entre deux processus en utilisant un service Linux tel que socketpair.
Le processus enfant envoie des messages au processus parent qui les afficher. Lorsque le process enfant envoie le message "exit" le programme se terminer.
Il est aussi demand\'e de fixer l'affinité des processus afin que le thread enfant effectue ces t\^aches sur le CPU 1 et le thread parent sur le CPU 0.
Il est également demandé d'ignorer les signaux SIGHUP, SIGINT, SIGQUIT, SIGABRT et SIGTERM.\\

Afin d'ignorer les signaux, nous utilisons la structure sigaction qui permet de modifier le comportement d'un signal.
Chaque handler de signal est assigné à SIG\_IGN, ce qui permet d'ignorer le signal.
Voici un extrait du code :

\begin{lstlisting}[style=CStyle, firstnumber=1]
	struct sigaction sa;
	sa.sa_handler = SIG_IGN;
	sigemptyset(&sa.sa_mask);
	sa.sa_flags = 0;
	sigaction(SIGHUP, &sa, NULL);
	sigaction(SIGINT, &sa, NULL);
	sigaction(SIGQUIT, &sa, NULL);
	sigaction(SIGABRT, &sa, NULL);
	sigaction(SIGTERM, &sa, NULL);
\end{lstlisting}
La création du socketpair se fait simplement avec ce bout de code :
\begin{lstlisting}[style=CStyle, firstnumber=1]
	int fd[2];
    if(socketpair(PF_LOCAL, SOCK_STREAM, 0, fd) < 0) {
        perror("socketpair");
        exit(1);
    }
\end{lstlisting}
Le param\`etre PF\_LOCAL permet de créer un socket local et SOCK\_STREAM permet de créer un socket de type TCP. La valeur 0 permet de spécifier le protocole par défaut (ici TCP).

Afin de crée les deux process, nous avons utilisons la fonction fork() qui permet de crée un processus enfant identique au processus parent.
Voici un extrait du programme apr\`es la fonction fork() :
\begin{lstlisting}[style=CStyle, firstnumber=1]
	pid = fork();
    if (pid == 0) { // child 
        close(fd[PARENTSOCKET]); 
        // set thread affinity
        if(setAffinity(1) == -1) { perror("sched_setaffinity");}
        child(fd[CHILDSOCKET]);
        close(fd[CHILDSOCKET]);
        exit(0);
    }
    else { // parent 
        close(fd[CHILDSOCKET]);
        // set thread affinity
        if(setAffinity(0) == -1) { perror("sched_setaffinity");}
        parent(fd[PARENTSOCKET]);
        close(fd[PARENTSOCKET]);
    }
    // must wait for child to exit
    // waitpid(pid, NULL, 0);
    wait(NULL);
\end{lstlisting}
La valeur de pid retourner par la fonction fork() permet de savoir si le processus est le parent ou l'enfant.
Ensuite il faut assigner l'affinité des processus, pour cela nous avons utiliser la fonction sched\_setaffinity() qui est appelée dans la fonction setAffinity() que nous avons cré\'ee.
Pour terminer, il suffit\ de lancer la fonction correspondante au processus (enfant, ou parent).
Et ne pas oublier d'effectuer une\ attente pour attendre que le processus enfant se termine,\ afin\ d'\'eviter les zombies.
La fonction setAffinity que nous avons créer utilise sched\_setaffinity, voici le code : \\
\begin{lstlisting}[style=CStyle, firstnumber=1]
	int setAffinity(int core) {
		// set thread affinity
		cpu_set_t cpuset;
		CPU_ZERO(&cpuset);
		// set this process to run on core 0
		CPU_SET(core, &cpuset);
		// here 0 mean use the calling process
		if(sched_setaffinity(0, sizeof(cpuset), &cpuset) == -1) {
	
			return -1;
		}
		return 0;
	}
\end{lstlisting}
La communication entre les deux process est assez simple \'etant donnée, que nous avons simplement 2 descripteurs de fichier, du point de vue de notre programme, c'est comme si nous allions écrire/lire dans un fichier.
Il ne reste plus qu'as lire le descripteur de fichier dans le parent, et d'écrire avec l'enfant.\\
\noindent\begin{minipage}{.50\textwidth}
\begin{lstlisting}[style=CStyle, caption=Processus Enfant, firstnumber=1]{Name}
void child(int socket) {
	// get the child socket
	int cpt = 0;
	int messageLength;
	bool exitProcess = false;
	while (!exitProcess) {
		messageLength = strlen(messages[cpt])+1;
		write(socket,messages[cpt],messageLength);
		if (strcmp(messages[cpt], EXIT_MESSAGE) == 0) {
			exitProcess = true;
		}
		// juste to give the time to the parent to read the message
		// because the parent could read two message at once and not see the exit message
		usleep(1000000); 
		cpt = (cpt + 1) % NUM_MESSAGE;
	}
	printf("Child exit\r\n");
}
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[style=CStyle, caption=Processus Parent, firstnumber=1]{Name}
void parent(int socket) {
	// get the parent socket
	char buffer[512];
	bool exitProcess = false;
	while (!exitProcess) {
		if(read(socket, buffer, sizeof(buffer)) <= 0) {
			perror("read");
			exit(1);
		}
		printf("Parent received: %s\r\n", buffer);
		if (strcmp(buffer, EXIT_MESSAGE) == 0) {
			exitProcess = true;
		}
	}
	printf("Parent exit\r\n");
}
\end{lstlisting}
\end{minipage}
Il faut tout de m\^eme faire attention \`a plusieurs choses, premi\`erement le parent peut recevoir deux messages en m\^eme temps avec la fonction read(), il faut donc faire attention a bien lire le message en entier.
Car on pourrait recevoir "message""exit", avec un z\'ero terminal entre les deux. Ce qui ferait que le programme ne s'arr\^eterait pas.
Ensuite la taille du buffer pourrait ne pas \^etre suffisante pour lire le message en entier, ce qui pourrait crée un buffer overflow.\\

% Synthese de ce qui as été appris/exercé
Lors de ce TP, nous avons appris \`a utiliser les socketpair afin de communiquer entre deux processus.
Nous avons aussi appris \`a ignorer des signaux, mais il aurait aussi été possible de les rediriger vers une fonction. Dans le but d'effectuer une action.
Gr\^ace\ \`a ce TP, nous avons appris \`a g\'erer un processus (création, affinité, communication, etc.). En utilisant les fonction fork(), schsed\_setaffinity(), socketpair(), etc...\\
% \lineeak

Ce labo a été plus compliquer que nous le pr\'ec\'edent, car nous avons eu de difficulté pour la r\'eception du message "exit". La solution retenue est simple, mais pourrait poser des probl\`emes.
Il serait mieux de regarder le nombre de bytes re\c{c}u, et de parser le message re\c{c}u dans diff\'erent string, en utilisant les z\'eros terminal.


\subsubsection{Exercice 2 CGroups Limitation memoire}\label{MPEx2}
% Exercice #2: Concevez une petite application permettant de valider la capacité des groupes de contrôle à limiter l’utili\'eation de la mémoire.
Dans cet exercice, l'objectif \'etait de montrer que les CGroups permettent de limiter l'utilisation de la m\'emoire d'un processus.
Pour faire cela, nous avons créer un programme qui alloue de la m\'emoire par block de 2MB, et qui remplit cette m\'emoire avec des 0.
voici ce programme : \\
\begin{lstlisting}[style=CStyle, caption=Allocation de memoire, firstnumber=1]{Name}
	#define NUM_BLOCKS 50
	#define MEGABYTE 1024 * 1024
	#define BLOCK_SIZE (2 * MEGABYTE)
	
	int main(void)
	{
		int i;
		char *ptr[NUM_BLOCKS];
		printf("Allocating memory...\n");
		for (i = 0; i < NUM_BLOCKS; i++)
		{
			getchar();
			printf("Allocating block %d\n", i);
			ptr[i] = malloc(BLOCK_SIZE * sizeof(char));
			if (ptr[i] == NULL){exit(EXIT_FAILURE);}
			memset(ptr[i], 0, BLOCK_SIZE);
		}
		for (i = 0; i < NUM_BLOCKS; i++){free(ptr[i]);}
		return 0;
	}
\end{lstlisting}
Afin de voir ce qu'il se passait, nous avons ajout\'e un print \`a chaque allocation pour voir \`a quel moment le programme serait stoppé.
Nous avons aussi ajout\'e un getchar() afin de pouvoir faire allouer un nouveau bloc de m\'emoire.
\linebreak
Avant de lancer ce code, il est n\'ecessaire de créer un groupe de contr\^ole, et de limiter la m\'emoire de ce groupe. Afin de simplifier l'utilisation de ce programme, nous avons écrit un script qui permet de faire cela.

\begin{lstlisting}[language=bash, firstnumber=1]{Name}
#!/bin/sh
mount -t tmpfs none /sys/fs/cgroup
mkdir /sys/fs/cgroup/memory
mount -t cgroup -o memory memory /sys/fs/cgroup/memory
mkdir /sys/fs/cgroup/memory/mem
echo $$ > /sys/fs/cgroup/memory/mem/tasks
echo 20M > /sys/fs/cgroup/memory/mem/memory.limit_in_bytes
./ex2
\end{lstlisting}
Ce script monte un syst\`eme de fichier tmpfs, puis monte un groupe de contr\^ole sur ce syst\`eme de fichier.
Ensuite il cr\'ee un groupe de contr\^ole, et limite la m\'emoire de ce groupe a 20MB \`a tous les processus qui y sont liés.
Enfin il lance le programme qui alloue de la m\'emoire.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\linewidth]{runEx2}
	\caption{ex\'ecution de l'exercice 2}
	\label{fig:ex2}
\end{figure}

Comme on peut le voir sur la figure \ref{fig:ex2}, le programme se fait tuer par le kernel lorsque l'on essaie d'allouer le 10e bloc de m\'emoire.
Ce qui correspond bien a la limite de 20MB que nous avons fixé.

\begin{enumerate}[label=\textbf{\arabic*}]
	\item \textbf{Quel effet a la commande echo \$\$ > ... sur les cgroups ?}\\
\$\$ en bash est le pid du processus courant. Donc cette commande permet d'écrire le pid du processus courant dans le fichier /sys/fs/cgroup/memory/mem/tasks. Ce qui permet de lier le processus courant au groupe de contr\^ole mem.
	
	\item \textbf{Quel est le comportement du sous-système memory lorsque le quota de mémoire est épuisé ? Pourrait-on le modifier ? Si oui, comment ?}\\
Lorsque le quota de m\'emoire est \'epuisé, le kernel tue le processus qui a essayé d'allouer de la m\'emoire.
Selon cette documentation \footnote{\href{https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-memory}{https://access.redhat.com/documentation/en-us/red\_hat\_enterprise\_linux/6/html/resource\_management\_guide/sec-memory}}.
Il est possible de l\'eg\`erement modifier le comportement en utilisant la commande :
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
	echo 1 > /sys/fs/cgroup/memory/mem/memory.oom_control
\end{lstlisting}
Cette commande d\'esactive le "OOM Killer", si un programme atteint ça limite de m\'emoire, il sera mis en pause jusqu'\`a ce qu'il y ait de la m\'emoire de disponible.

	\item \textbf{Est-il possible de surveiller/vérifier l’état actuel de la mémoire ? Si oui, comment ?}\\
Afin de surveiller la m\'emoire, il y a plusieurs options simples, comme la commande top, htop.
la fonction free permet aussi de voir l'\'etat de la m\'emoire. Mais elle donne des informations sur la m\'emoire globale, et non sur un processus en particulier.
Il est aussi possible de voir l'\'etat de la m\'emoire d'un processus en utilisant la commande :
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
	cat /proc/<PID>/stat | awk '{print $23}'
\end{lstlisting}
\end{enumerate}

% \linebreak

Nous ne connaissions pas du tout les CGroups, ce qui a rendu cet exercice tr\`es int\'eressant.
Nous avons réussi \`a faire effectuer l'exercice, mais \`a un certain moment la limitation de m\'emoire ne fonctionnait pas.
Il faudrait que l'on regarde plus en d\'etail comment fonctionne les CGroups, et comment les utiliser, la structure et le nombre de fichiers pr\'esents dans le syst\`eme de fichier /sys/fs/cgroup/memory/ est assez impressionnant.
Toutefois, il est bon de savoir qu'il est possible de limiter la m\'emoire d'un processus, et de voir comment cela fonctionne.

\subsubsection{Exercice 3 CGroups Controle du CPU}\label{MPEx3}
% Afin de valider la capacité des groupes de contrôle de limiter l’utilisation des CPU, 
% concevez une petite application composée au minimum de 2 processus utilisant le 100% des ressources du processeur.
Dans cet exercice, l'objectif est de limiter l'utilisation du CPU par un processus.
Pour cela, nous avons cré\'e un programme qui lance 2 processus faisant des calculs afin de charger les CPU. 
Nous avons utiliser la fonction fork() vue dans l'exercice 1 (\ref{MPEx1}).

Ce programme nous permet de simplement lancer 2 processus qui vont charger les CPU.\\
\noindent\begin{minipage}{.50\textwidth}
	\begin{lstlisting}[style=CStyle, caption=Processus Enfant, firstnumber=1]{Name}
	int main(void)
	{
		pid_t pid;
		pid = fork();
		if (pid == 0) { // child
			compute();
			exit(0);
		}
		else { // parent
			compute();
		}
		// must wait for child to exit
		// waitpid(pid, NULL, 0);
		wait(NULL);
		return 0;
	}
	\end{lstlisting}
	\end{minipage}\hfill
	\begin{minipage}{.45\textwidth}
	\begin{lstlisting}[style=CStyle, caption=Processus Parent, firstnumber=1]{Name}
	void compute() {
		int a = 0;
		while (1) {
			// do some random computation
			a = (a + 1) % 1000000;
		}
	}
	\end{lstlisting}
\end{minipage}

Il reste \`a configurer les CGroups pour limiter l'utilisation du CPU par les processus. Pour faire cela, les lignes de commande nous ont été fournies.

\begin{lstlisting}[language=bash, firstnumber=1]{Name}
#!/bin/sh
mkdir /sys/fs/cgroup/cpuset
mount -t cgroup -o cpu,cpuset cpuset /sys/fs/cgroup/cpuset
mkdir /sys/fs/cgroup/cpuset/high
mkdir /sys/fs/cgroup/cpuset/low
echo 3 > /sys/fs/cgroup/cpuset/high/cpuset.cpus
echo 0 > /sys/fs/cgroup/cpuset/high/cpuset.mems
echo 2 > /sys/fs/cgroup/cpuset/low/cpuset.cpus
echo 0 > /sys/fs/cgroup/cpuset/low/cpuset.mems
echo $$ > /sys/fs/cgroup/cpuset/high/tasks
./ex3
\end{lstlisting}
Pour simplifier l'exercice, nous avons fait deux scripts bash, un qui lance le processus dans le groupe high, et un autre qui le lance dans le groupe low.
La seule diff\'erence se trouve \`a la ligne 10, ou nous changeons "high" en "low".


\begin{enumerate}[label=\textbf{\arabic*}]
	\item \textbf{Les 4 dernières lignes sont obligatoires pour que les prochaines commandes fonctionnent correctement. Pouvez-vous en donner la raison ?}\\
	La documentation trouvable ici : \footnote{\href{https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpuset}{https://access.redhat.com/documentation/en-us/red\_hat\_enterprise\_linux/6/html/resource\_management\_guide/sec-cpuset}}
	nous indique que cpuset.cpus et cpuset.mems sont mandatoires pour chaque cgroup.
	le fichier cpuset.cpus permet de speficier sur quels CPU le processus peut s'ex\'ecuter, il est possible de sp\'ecifier un intervalle de cpu, ou une liste.
	Le fichier cpuset.mems permet de sp\'ecifier quels n\oe{}uds m\'emoires le processus peut utiliser.
	
	
	Il est n\'ecessaire de sp\'ecifier sur quelle CPU les processus vont s'ex\'ecuter
	\item \textbf{Ouvrez deux shells distincts et placez une dans le cgroup high et l’autre dans le cgroup low, par exemple :}\\
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
$ ssh root@192.168.0.14
$ echo $$ > /sys/fs/cgroup/cpuset/low/tasks
\end{lstlisting}
\textbf{Lancez ensuite votre application dans chacun des shells. Quel devrait être le bon comportement ? Pouvez-vous le vérifier ?}\\
Le programme appartenant au cgroupe high devrait tourner sur le CPU 3, alors que le programme appartenant au groupe low devrait tourner sur le CPU 2.
De plus comme un seul CPU est associé \`a 2 processus, le temps CPU devrait \^etre partagé entre les deux processus. La charge sera donc toujours de 100\% sur un CPU, mais partagés \`a 50\% entre les deux processus.
Afin de v\'erifier cela, nous pouvons utiliser la commande htop, qui nous permet de voir l'utilisation des CPU.
Voici l'ex\'ecution du script runEx3Low.sh :
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{MPEx3Low}
	\caption{Ex\'ecution du script runEx3Low.sh}
	\label{fig:MPEx3Low}
\end{figure}
Sans arr\^eter le script runEx3Low.sh, nous pouvons lancer le script runEx3High.sh :
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{MPEx3HighLow}
	\caption{Ex\'ecution du script runEx3High.sh}
	\label{fig:MPEx3High}
\end{figure}

En modifiant les lignes 6 et 8, on peut faire en sorte que les processus se r\'epartissent sur les 4 CPU, et non pas seulement 2.
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
echo 2-3 > /sys/fs/cgroup/cpuset/high/cpuset.cpus
echo 0 > /sys/fs/cgroup/cpuset/high/cpuset.mems
echo 0-1 > /sys/fs/cgroup/cpuset/low/cpuset.cpus
echo 0 > /sys/fs/cgroup/cpuset/low/cpuset.mems
\end{lstlisting}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{MPEx3HighLow4CPU}
	\caption{Ex\'ecution des deux scripts avec 4 CPU}
	\label{fig:MPEx3HighLow4CPU}
\end{figure}


	\item \textbf{Sachant que l’attribut cpu.shares permet de répartir le temps CPU entre différents cgroups, comment devrait-on procéder pour lancer deux tâches distinctes sur le cœur 4 de notre processeur et attribuer 75\% du temps CPU à la première tâche et 25\% à la deuxième ?}\\

Ici on veut faire tourner tous nos programmes sur le CPU4, donc un peut \'ecrire.
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
echo 3 > /sys/fs/cgroup/cpuset/high/cpuset.cpus
echo 0 > /sys/fs/cgroup/cpuset/high/cpuset.mems
echo 3 > /sys/fs/cgroup/cpuset/low/cpuset.cpus
echo 0 > /sys/fs/cgroup/cpuset/low/cpuset.mems
# set the cpu.shares
echo 768 > /sys/fs/cgroup/cpuset/high/cpu.shares
echo 256 > /sys/fs/cgroup/cpuset/low/cpu.shares
# change high to low for the other script
echo $$ > /sys/fs/cgroup/cpuset/high/tasks 
./ex3
\end{lstlisting}
Pour ce test, nous avons réutilis\'e le programme qui g\'en\`ere deux processus, nous aurons donc 2 processus qui se partageront 75\% du temps CPU, et deux autres pour les 25\% restant.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{runEx3Share}
	\caption{Ex\'ecution des deux scripts avec 4 CPU}
	\label{fig:runEx3Share}
\end{figure}
On peut observer sur la figure \ref{fig:runEx3Share} que les deux processus on 37.5\% du temps CPU, et les deux autres 12.5\%.
ce qui fait bien 75\% et 25\%.

Ce TP était tr\`es proche du pr\'ec\'edent, mais nous avons appris a g\'erer les ressources CPU alloué a un processus, et comment les partager entre plusieurs processus.
\end{enumerate}


\subsection{Outils d'analyse de performance pour Linux}
Dans cette partie, nous allons nous familiariser avec l'outil perf de Linux. Cet outil permet de mesurer les performances d'un programme. Il est possible de mesurer le temps d'ex\'ecution d'un programme, le nombre de cycles d'horloge, le nombre d'instructions, le nombre de caches miss, etc.\\

tout d'abord, nous commen\c{c}ons par ajouter binutils dans buildroot :
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
$ cd /buildroot
$ make menuconfig
$ Target packages -> Development tools -> binutils
$ Target packages -> Development tools -> binutils binaries
$ make -j4
\end{lstlisting}

Puis nous installons le nouveau buildroot en prenant garde de ne pas effacer la configuration dans /etc/fstab, en utilisant les commandes fournies dans le cours.
Apr\`es avoir v\'erifié que perf soit bien installée, nous avons lancé la commande perf sur l'exercice 1 :
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
$ perf stat ./ex1
\end{lstlisting}
Et nous avons obtenu le r\'esultat suivant :
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{perfEx1}
	\caption{Ex\'ecution des deux scripts avec 4 CPU}
	\label{fig:runEx3Share}
\end{figure}

\begin{enumerate}[label=\textbf{\arabic*}]
	\item \textbf{Ce programme contient une erreur triviale qui empêche une utilisation optimale du cache. De quelle erreur s’agit-il ?}
L'erreur est que le tableau est parcouru en entier entre chaque incr\'ement, si tout le tableau rentrait dans la cache, cela pourrait ne pas poser de probl\`eme.
Mais ici, le tableau est trop grand pour rentrer dans le cache, et donc a chaque incr\'ement, le cache est vidé, et le tableau est rechargé dans le cache, ce qui prend du temps.
Une modification simple pour rendre ce code plus efficace serait de d\'eplacer la boucle d'incr\'ement \`a\ l'int\'erieur des deux boucles.

\noindent\begin{minipage}{.45\textwidth}
	\begin{lstlisting}[style=CStyle, caption=Code fournis, firstnumber=1]{Name}
for (k = 0; k < 10; k++)
{
	for (i = 0; i < SIZE; i++)
	{
		for (j = 0; j < SIZE; j++)
		{
			array[j][i]++;
		}
	}
}
	\end{lstlisting}
	\end{minipage}\hfill
	\begin{minipage}{.45\textwidth}
	\begin{lstlisting}[style=CStyle, caption=Code modifié, firstnumber=1]{Name}
for (i = 0; i < SIZE; i++)
{
	for (j = 0; j < SIZE; j++)
	{
		for (k = 0; k < 10; k++)
		{
			// memory access already in cache
			array[j][i]++;
		}
	}
}
	\end{lstlisting}
\end{minipage}

Afin d'avoir un point de comparaison, nous avons lancé le programme de base avec la commande perf :
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
$ perf stat -e cache-misses ./ex1
\end{lstlisting}
Et nous avons obtenu le r\'esultat suivant :
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{perfEx1Cache}
	\caption{Ex\'ecution des deux scripts avec 4 CPU}
	\label{fig:runEx3Share}
\end{figure}

	\item \textbf{Corrigez l’erreur, recompilez et mesurez à nouveau le temps d’exécution (soit avec perf stat, soit avec la commande time). Quelle amélioration constatez-vous ?}


Puis nous avons relancé le programme avec la correction :
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{perfEx1CacheOpti}
	\caption{Ex\'ecution des deux scripts avec 4 CPU}
	\label{fig:runEx3Share}
\end{figure}
le temps est passé de 41.7s a 5.8s et le nombre de caches miss de 407143880 a 42339357. Il y a 9.6x moins de cache miss, et le temps d'ex\'ecution est 7.2x plus rapide.\\
En modifiant une simple boucle

\item \textbf{Relevez les valeurs du compteur L1-dcache-load-misses pour les deux versions de l’application. Quel facteur constatez-vous entre les deux valeurs ?}

% array of two line and two column
\begin{center}
	\begin{tabular}{|c|c|c|}
		\hline
		& \textbf{Sans correction} & \textbf{Avec correction} \\
		\hline
		\textbf{L1-dcache-load-misses} & 406895610 & 42289308 \\
		\hline
		\textbf{cache-misses} & 407143880 & 42339357 \\
		\hline
	\end{tabular}
\end{center}
Les r\'esultats sont similaires aux deux r\'esultats pr\'ec\'edents, il y a 9.6x moins\ de\ cache\ miss et le temps d'ex\'ecution est 7.2x plus rapide.


\'eitem \textbf{Décrivez brièvement ce que sont les évènements suivants :}
% add a sub-list to the question
\begin{enumerate}[label=\textbf{\alph*}]
	\item \textbf{instructions :} le nombre d'instructions ex\'ecuté
	\item \textbf{cache-misses :} le nombre de caches miss
	\item \textbf{branch-misses :} le nombre de branch miss
	\item \textbf{L1-dcache-load-misses :} le nombre de caches miss de niveau 1
	\item \textbf{cpu-migrations :} le nombre de migrations de processus
	\item \textbf{context-switches :} le nombre de changements de contexte
\end{enumerate}

\item \textbf{Lors de la présentation de l’outil perf, on a vu que celui-ci permettait de profiler une application avec très peu d’impacts sur les performances. En utilisant la commande time, mesurez le temps d’exécution de notre application ex1 avec et sans la commande perf stat}\\
L'ex\'ecution de la commande perf stat a pris 5.477 secondes, et l'ex\'ecution de la commande time a pris 5.07 secondes. Mais il faudrait effectuer plusieurs\ lancements ps\ lancementsune moyenne plus pr\'ecise.
On peut observer que le programme prend 0.4s de plus avec perf stat, ce qui est tr\`es peu, et donc on peut dire que perf stat a tresse peu d'impact sur les performances.

\end{enumerate}

% exercice 2
\textbf{Exercice 2 :}
\begin{enumerate}[label=\textbf{\arabic*}]

\item \textbf{Décrivez en quelques mots ce que fait ce programme.}\\
Le programme commence par remplir un tableau de 65536 entier avec des valeurs aléatoires entre 0 et 512 (en réalité les valeurs ne sont pas aléatoires, car la seed est toujours la m\^eme, la somme sera toujours la m\^eme).
Ensuite deux boucle for effectue 10000 fois la somme des valeurs plus grandes ou \'egales à 256.

\item \textbf{Mesurez le temps d’exécution}\\
Voici le r\'esultat de l'ex\'ecution du programme :


\begin{lstlisting}[language=bash, firstnumber=1]{Name}
# time ./ex2 
sum=125454290000
real	0m 26.19s
user	0m 26.11s
sys	0m 0.00s
\end{lstlisting}

Le programme prend 26,19 secondes pour s'ex\'ecuter.
dans le prochain test, nous allons essayer de trier le tableau en ajoutant ces lignes de code :
\begin{lstlisting}[style=CStyle, caption=Code modifié, firstnumber=1]{Name}
static int compare (const void* a, const void* b)
{
    return *(short*)a - *(short*)b;
}
qsort(array, SIZE, sizeof(short), compare);
\end{lstlisting}

Le temps est \`a\ pr\'esent de 23.45 secondes, nous avons gagn\'e 2.74 secondes.

\item \textbf{À l’aide de l’outil perf et de sa sous-commande stat, en utilisant différents compteurs déterminez pourquoi le programme modifié s’exécute plus rapidement.}\\

D'apr\`es nos mesures, le gain de vitesse vient des pr\'edictions de branchement.
Voici les r\'esultats de perf stat : (les autres r\'esultats\ \ d'event\ sont\ similaires).\\
32788425s\ dans\ les\ deux\ ex\'ecutions9.      branch-misses             \#   33.17\% of all branches\\
842261         branch-misses             \#    0.08\% of all branches\\

Le fait que le tableau soit trié permet d'avoir de meilleure pr\'ediction de branchement, donc le pipeline est moins souvent cassé.
\end{enumerate}


% Exercice 3

\textbf{Exercice 3 :}
\begin{enumerate}[label=\textbf{\arabic*}]

\item \textbf{Compilez l’application et profilez l’application avec perf record :}\\
Nous ex\'ecutons la commande suivante :
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
perf record --call-graph dwarf -e cpu-clock -F 75 \
./read-apache-logs access_log_NASA_Jul95_samples
\end{lstlisting}

un fichier report.data est généré, que nous analysons avec la commande suivante :
\begin{lstlisting}[language=bash, firstnumber=1]{Name}
perf report --no-children --demangle
\end{lstlisting}
\item \textbf{Avec les instructions précédentes, déterminez quelle fonction de notre application fait (indirectement) appel à std::operator==<char>.}\\

Le probl\`eme vient de cette fonction :
\begin{lstlisting}[style=CStyle, caption=Extrait de hostcounter.cpp, firstnumber=1]{Name}
bool HostCounter::isNewHost(std::string hostname)
{
    return std::find(myHosts.begin(), myHosts.end(), hostname) == myHosts.end();
}
\end{lstlisting}

\item \textbf{Maintenant que vous savez quelle fonction utilise le plus de ressources CPU, trouvez une optimisation du code permettant de réduire drastiquement le temps d’exécution (vous devriez arriver à quelques dixièmes de secondes pour le fichier sample).}\\
Nous modifions le code afin d'utiliser la structure set, au lieu de vector et testons le temps d'ex\'ecution avec la commande time.
Le temps est \`a\ pr\'esent de 1.49s, contre 2 minutes et 18 secondes avant la modification.
En ex\'ecutant \`a nouveau la commande perf record, nous pouvons voir que les fonctions memcmp et cfree, sont les plus utilisées.

\item \textbf{Décrivez comment devrait-on procéder pour mesurer la latence et la gigue d’interruption, ceci aussi bien au niveau du noyau (kernel space) que de l’application (user space)}\\
Dans le cas d'un syst\`eme embarqué avec une routine d'interruption assigné \`a une pin, on pourrait envoyer un signal carré sur la pin d'interruption.
Puis inverser l'\'etat d'une pin de sortie, dans la routine d'interruption.
Ensuite \`a l'aide d'un oscilloscope, on pourrait mesurer la latence et la gigue d'interruption. En effectuant des moyennes, et en calculant l'\'ecart type.
\end{enumerate}


\section{Concluerion}

blabla

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\printbibliography % Output the bibliography

%----------------------------------------------------------------------------------------

\end{document}